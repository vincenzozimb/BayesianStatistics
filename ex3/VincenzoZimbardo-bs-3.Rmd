---
title: Homework 3 - Bayesian Statistics 2023
author: Vincenzo Zimbardo 
output: html_document
bibliography: references.bib
---

# Exercise 1: Mixture of exponential data

```{r echo=FALSE}
set.seed(12345)
```

Suppose a company obtains boxes of electronic parts from a particular supplier. 
It is known that $80\%$ of the lots are acceptable and the lifetimes of the "acceptable" parts follow an exponential distribution with mean $\lambda_A$.
Unfortunately, $20\%$ of the lots are unacceptable and the lifetimes of the "bad" parts are exponential with mean $\lambda_B$, 
where $\lambda_A > \lambda_B$. Suppose $y_1, \ldots, y_n$, are the lifetimes of $n$ inspected parts that can come from either acceptable
and unacceptable lots. 

The following lifetimes are observed from a sample of $30$ parts:
```{r echo=TRUE}
# Lifetimes data 
data <- c(0.98, 0.29, 36.70, 10.39, 39.93)
data <- c(data, c(14.57, 1.67, 18.81, 4.87, 20.24))
data <- c(data, c(0.08, 7.08, 14.89, 18.64, 8.69))
data <- c(data, c(0.18, 32.21, 0.16, 1.46, 0.58))
data <- c(data, c(86.49, 18.51, 0.72, 2.69, 2.58))
data <- c(data, c(41.79, 50.38, 0.77, 24.60, 0.91))
```


The $y_i$s are a random sample from the mixture distribution
$$  
h(y \vert  \lambda_A, \lambda_B) = p \frac{\exp(-y/\lambda_A)}{\lambda_A} + (1-p) \frac{\exp(-y/\lambda_B)}{\lambda_B} \ ,
$$
where $p=0.8$. Suppose $(\lambda_A, \lambda_B)$ are assigned the noninformative prior proportional to $1/(\lambda_A \ \lambda_B)$. 
The following function \texttt{log.exponential.mix} computes the log posterior density of the transformed parameters 
$\theta = (\theta_A, \theta_B) = (\log \lambda_A, \log \lambda_B)$:

```{r echo=TRUE}  
log.exponential.mix <- function(theta) {
  lambda.A <- exp(theta[1])
  lambda.B <- exp(theta[2])  
  res <- sum(log(0.8*dexp(data,1/lambda.A)+(1-0.8)*dexp(data,1/lambda.B))) 
  return (res)
}
```
    
### Construct a contour plot of $(\theta_A, \theta_B)$ over the rectangle $(1,4) \times (-2,8)$

```{r echo=TRUE}
# Create data
x <- seq(1, 4, 0.01)
y <- seq(-2, 8, 0.01)
z <- matrix(nrow = length(x), ncol = length(y))

for (i in 1:length(x)) {
  for (j in 1:length(y)) {
    z[i, j] <- log.exponential.mix(theta = c(x[i], y[j]))
  }
}

# Create the contour plot
contour(x, y, z, main = "Contour Plot", nlevels=15, xlab = expression(theta[A]), ylab = expression(theta[B]))
```

### Using the function \texttt{optim} search for the posterior mode with a starting guess of $(\theta_A, \theta_B) = (3,0)$.

```{r echo=TRUE}
start1        <- c(3, 0)
optimization1 <- optim(par=start1, fn=log.exponential.mix, control=list(fnscale=-1), hessian = TRUE)
mode1         <- optimization1$par
```

```{r echo=FALSE}
print(paste0("Mode (", round(mode1[1],4), ",", round(mode1[2],4), ")"))
```

### Search for the posterior mode with a starting guess $(\theta_A, \theta_B) = (2,4)$.

```{r echo=TRUE}
start2        <- c(2, 4)
optimization2 <- optim(par=start2, fn=log.exponential.mix, control=list(fnscale=-1), hessian = TRUE)
mode2         <- optimization2$par
```

```{r echo=FALSE}
print(paste0("Mode (", round(mode2[1],4), ",", round(mode2[2],4), ")"))
```

### Explain why you obtain different estimates of the posterior mode in the previous two points.  

The default method in the `optim` function in `R` is the one of @10.1093/comjnl/7.4.308, which is a deterministic numerical method. 
It assumes the existence of a unique maximum in the area of the search, as explained by the authors.
For this reason, the two different initial conditions give rise to two different results. As it is possible to note from the contour plot,
with the first initial condition the algorithm converges to the local minimum in the lower-right part of the plot, while the second initial condition is driven
away from it, toward another local minumum.

To overcome this problem, in the case of multimodal function to be optimized, stochastic methods are used instead.
Indeed, using the `SANN` method in the function `optim`, which implement a simulated annealing algorithm, the following results are obtained: 

```{r echo=TRUE}
optimization <- optim(par=start1, fn=log.exponential.mix, control=list(fnscale=-1), method="SANN", hessian=TRUE)
mode         <- optimization$par
```

```{r echo=FALSE}
print(paste0("Mode (", round(mode[1],4), ",", round(mode[2],4), ")"))
```

```{r echo=TRUE}
optimization <- optim(par=start2, fn=log.exponential.mix, control=list(fnscale=-1), method="SANN", hessian=TRUE)
mode         <- optimization$par
```

```{r echo=FALSE}
print(paste0("Mode (", round(mode[1],4), ",", round(mode[2],4), ")"))
```

From that it can be deduced which one is the global minimum.

### Use a normal approximation to construct a random walk Metropolis chain for sampling the posterior of $\theta= (\log(\lambda_A), \log(\lambda_B))$. Run the chain for $10000$ iterations, and costruct density estimates for $\log(\lambda_A)$ and $\log(\lambda_B)$.

```{r echo=TRUE}
# Laplace approximation
mode <- mode1
V <- -solve(optimization1$hessian)
```

Implementation of the random walk Metropolis-Hastings algorithm
```{r echo=TRUE}
library(mvtnorm)
# target distribution
target <- function(x){
  return (exp(log.exponential.mix(x)))
}
# Random Walk Metropolis-Hastings
RWMH <- function(x_start, target, n){
  samples <- matrix(nrow=n+1, ncol=2)
  samples[1,] <- x_start
  x_curr <- x_start
  # iteration
  for (i in 1:n){
    # sample from proposal
    z_prop <- mvrnorm(n=1, mu=c(0,0), Sigma=V)
    # calculate acceptance ratio
    x_prop <- x_curr + z_prop
    acceptance_ratio <- target(x_prop) / target(x_curr)
    # accept or reject the proposal step
    if (runif(1) < acceptance_ratio) {
      x_curr <- x_prop
    }
    samples[i+1,] <- x_curr
  }
  # return samples
  return (samples)
}
```

Sampling
```{r echo=TRUE}
# Set the parameters for the Random Walk Metropolis-Hastings algorithm
x_start <- c(3,0)  # Initial value of the Markov chain
n <- 10000  # Number of iterations
# Run the Random Walk Metropolis-Hastings algorithm
samples <- RWMH(x_start, target, n)
samples <- samples[-1,]
```

```{r echo=FALSE}
# trace  to check convergence
par(mfrow = c(1, 2))
plot(1:n,samples[,1], type="l", xlab = expression(i), ylab = expression(theta[A]^(i)))
plot(1:n,samples[,2], type="l", xlab = expression(i), ylab = expression(theta[B]^(i)))
# Restore default plot options
par(mfrow = c(1, 1))
```

From the trace plots is is possible to deduce that no burn-in phase is necessary. The reason for that is that a good starting point 
(the mode obtained from the Laplace's approximation) has been used. 
On the other hand, if another initial condition is chosen (for example the local maximum $(2,4)$) a burn-in phase could not be optional. 

Correlation analysis
```{r echo=TRUE}
acf(samples)
```

In order to reduce the autocorrelation in the sample we could use a thinning procedure (increasing the computation time) or try to randomly permute the obtained sequence:
```{r echo=TRUE}
# permute the samples to lower the autocorrelation
samples[,1] <- sample(samples[,1])
samples[,2] <- sample(samples[,2])
acf(samples)
```

In this way the autocorrelation is drastically reduced and the sample can be considered as an IID sample.


The final sample is summarized in the following $2D$ histogram:
```{r echo=FALSE, message=FALSE}
library(gplots)
hist_obj <- hist2d(samples, col=c("aliceblue", heat.colors(12)), main="RWMH sample histogram", xlab = expression(theta[A]), ylab = expression(theta[B]))
```

Finally, density estimates for $\log(\lambda_A)$ and $\log(\lambda_B)$ can be constructed:
```{r echo=TRUE}
theta_A <- mean(samples[,1])
theta_B <- mean(samples[,2])
``` 

```{r echo=FALSE}
print(paste0("theta_A", ":", round(theta_A,4)))
print(paste0("theta_B", ":", round(theta_B,4)))
```


### Construct a Metropolis within Gibbs samples, i.e., use a Metropolis algorithm to sample from $\log(\lambda_B) \lvert \log(\lambda_A)$ and then do the viceversa. Also run the chain for $10000$ iterations and costruct density estimates for $\log(\lambda_A)$ and $\log(\lambda_B)$.   


```{r echo=FALSE}
# Clear workspace
# rm(list=ls())
```


<!--------------------------------------------------------------------------------------------------------------------------------------------------->

# Exercise 2

<!--------------------------------------------------------------------------------------------------------------------------------------------------->

# Exercise 3

<!--------------------------------------------------------------------------------------------------------------------------------------------------->

# Exercise 4

<!--------------------------------------------------------------------------------------------------------------------------------------------------->

# References

<!--------------------------------------------------------------------------------------------------------------------------------------------------->