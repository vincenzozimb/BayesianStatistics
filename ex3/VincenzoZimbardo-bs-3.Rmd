---
title: Homework 3 - Bayesian Statistics 2023
author: Vincenzo Zimbardo 
output: html_document
bibliography: references.bib
---

# Exercise 1: Mixture of exponential data

```{r echo=FALSE}
set.seed(12345)
```

Suppose a company obtains boxes of electronic parts from a particular supplier. 
It is known that $80\%$ of the lots are acceptable and the lifetimes of the "acceptable" parts follow an exponential distribution with mean $\lambda_A$.
Unfortunately, $20\%$ of the lots are unacceptable and the lifetimes of the "bad" parts are exponential with mean $\lambda_B$, 
where $\lambda_A > \lambda_B$. Suppose $y_1, \ldots, y_n$, are the lifetimes of $n$ inspected parts that can come from either acceptable
and unacceptable lots. 

The following lifetimes are observed from a sample of $30$ parts:
```{r echo=TRUE}
# Lifetimes data 
data <- c(0.98, 0.29, 36.70, 10.39, 39.93)
data <- c(data, c(14.57, 1.67, 18.81, 4.87, 20.24))
data <- c(data, c(0.08, 7.08, 14.89, 18.64, 8.69))
data <- c(data, c(0.18, 32.21, 0.16, 1.46, 0.58))
data <- c(data, c(86.49, 18.51, 0.72, 2.69, 2.58))
data <- c(data, c(41.79, 50.38, 0.77, 24.60, 0.91))
```


The $y_i$s are a random sample from the mixture distribution
$$  
h(y \vert  \lambda_A, \lambda_B) = p \frac{\exp(-y/\lambda_A)}{\lambda_A} + (1-p) \frac{\exp(-y/\lambda_B)}{\lambda_B} \ ,
$$
where $p=0.8$. Suppose $(\lambda_A, \lambda_B)$ are assigned the noninformative prior proportional to $1/(\lambda_A \ \lambda_B)$. 
The following function \texttt{log.exponential.mix} computes the log posterior density of the transformed parameters 
$\theta = (\theta_A, \theta_B) = (\log \lambda_A, \log \lambda_B)$:

```{r echo=TRUE}  
log.exponential.mix <- function(theta) {
  lambda.A <- exp(theta[1])
  lambda.B <- exp(theta[2])  
  res <- sum(log(0.8*dexp(data,1/lambda.A)+(1-0.8)*dexp(data,1/lambda.B))) 
  return (res)
}
```
    
### Construct a contour plot of $(\theta_A, \theta_B)$ over the rectangle $(1,4) \times (-2,8)$

```{r echo=TRUE}
# Create data
x <- seq(1, 4, 0.01)
y <- seq(-2, 8, 0.01)
z <- matrix(nrow = length(x), ncol = length(y))

for (i in 1:length(x)) {
  for (j in 1:length(y)) {
    z[i, j] <- log.exponential.mix(theta = c(x[i], y[j]))
  }
}

# Create the contour plot
contour(x, y, z, main = "Contour Plot", nlevels=15, xlab = expression(theta[A]), ylab = expression(theta[B]))
```

### Using the function \texttt{optim} search for the posterior mode with a starting guess of $(\theta_A, \theta_B) = (3,0)$.

```{r echo=TRUE}
start1        <- c(3, 0)
optimization1 <- optim(par=start1, fn=log.exponential.mix, control=list(fnscale=-1), hessian = TRUE)
mode1         <- optimization1$par
```

```{r echo=FALSE}
print(paste0("Mode (", round(mode1[1],4), ",", round(mode1[2],4), ")"))
```

### Search for the posterior mode with a starting guess $(\theta_A, \theta_B) = (2,4)$.

```{r echo=TRUE}
start2        <- c(2, 4)
optimization2 <- optim(par=start2, fn=log.exponential.mix, control=list(fnscale=-1), hessian = TRUE)
mode2         <- optimization2$par
```

```{r echo=FALSE}
print(paste0("Mode (", round(mode2[1],4), ",", round(mode2[2],4), ")"))
```

### Explain why you obtain different estimates of the posterior mode in the previous two points.  

The default method in the `optim` function in `R` is the one of @10.1093/comjnl/7.4.308, which is a deterministic numerical method. 
It assumes the existence of a unique maximum in the area of the search, as explained by the authors.
For this reason, the two different initial conditions give rise to two different results. As it is possible to note from the contour plot,
with the first initial condition the algorithm converges to the local minimum in the lower-right part of the plot, while the second initial condition is driven
away from it, toward another local minumum.

To overcome this problem, in the case of multimodal function to be optimized, stochastic methods are used instead.
Indeed, using the `SANN` method in the function `optim`, which implement a simulated annealing algorithm, the following results are obtained: 

```{r echo=TRUE}
optimization <- optim(par=start1, fn=log.exponential.mix, control=list(fnscale=-1), method="SANN", hessian=TRUE)
mode         <- optimization$par
```

```{r echo=FALSE}
print(paste0("Mode (", round(mode[1],4), ",", round(mode[2],4), ")"))
```

```{r echo=TRUE}
optimization <- optim(par=start2, fn=log.exponential.mix, control=list(fnscale=-1), method="SANN", hessian=TRUE)
mode         <- optimization$par
```

```{r echo=FALSE}
print(paste0("Mode (", round(mode[1],4), ",", round(mode[2],4), ")"))
```

From that it can be deduced which one is the global minimum.

### Use a normal approximation to construct a random walk Metropolis chain for sampling the posterior of $\theta= (\log(\lambda_A), \log(\lambda_B))$. Run the chain for $10000$ iterations, and costruct density estimates for $\log(\lambda_A)$ and $\log(\lambda_B)$.

```{r echo=TRUE}
# Laplace approximation
mode <- mode1
V <- -solve(optimization1$hessian)
```

Implementation of the random walk Metropolis-Hastings algorithm
```{r echo=TRUE}
library(MASS)
# target distribution
target <- function(x){
  return (exp(log.exponential.mix(x)))
}
# Random Walk Metropolis-Hastings
RWMH <- function(x_start, target, n){
  samples <- matrix(nrow=n+1, ncol=2)
  samples[1,] <- x_start
  x_curr <- x_start
  # iteration
  for (i in 1:n){
    # sample from proposal
    z_prop <- mvrnorm(n=1, mu=c(0,0), Sigma=V)
    # calculate acceptance probability
    x_prop <- x_curr + z_prop
    acceptance_prob <- min(1, target(x_prop) / target(x_curr))
    # accept or reject the proposal step
    if (runif(1) < acceptance_prob) {
      x_curr <- x_prop
    }
    samples[i+1,] <- x_curr
  }
  # return samples
  return (samples)
}
```

Sampling
```{r echo=TRUE}
# Set the parameters for the Random Walk Metropolis-Hastings algorithm
x_start <- c(3,0)  # Initial value of the Markov chain
n <- 10000  # Number of iterations
# Run the Random Walk Metropolis-Hastings algorithm
samples <- RWMH(x_start, target, n)
samples <- samples[-1,]
```

```{r echo=FALSE}
# trace  to check convergence
par(mfrow = c(1, 2))
plot(1:n,samples[,1], type="l", xlab = expression(i), ylab = expression(theta[A]^(i)))
plot(1:n,samples[,2], type="l", xlab = expression(i), ylab = expression(theta[B]^(i)))
# Restore default plot options
par(mfrow = c(1, 1))
```

From the trace plots is is possible to deduce that no burn-in phase is necessary. The reason for that is that a good starting point 
(the mode obtained from the Laplace's approximation) has been used. 
On the other hand, if another initial condition is chosen (for example in the proximity $(2,4)$ of the other local maximum) a burn-in phase could not be optional. 

Correlation analysis
```{r echo=TRUE}
acf(samples)
```

In order to reduce the autocorrelation in the sample we could use a thinning procedure (increasing the computation time) or try to randomly permute the obtained sequence:
```{r echo=TRUE}
# permute the samples to lower the autocorrelation
samples[,1] <- sample(samples[,1])
samples[,2] <- sample(samples[,2])
acf(samples)
```

In this way the autocorrelation is drastically reduced and the sample can be considered as an IID sample.

The final sample is summarized in the following $2D$ histogram:
```{r echo=FALSE, message=FALSE}
library(gplots)
hist_obj <- hist2d(samples, col=c("aliceblue", heat.colors(12)), main="RWMH sample histogram", xlab = expression(theta[A]), ylab = expression(theta[B]))
```

Finally, density estimates for $\log(\lambda_A)$ and $\log(\lambda_B)$ can be constructed:

```{r echo=TRUE}
theta_A <- mean(samples[,1])
theta_B <- mean(samples[,2])
```

```{r echo=FALSE}
print(paste0("theta_A", ":", round(theta_A,4)))
print(paste0("theta_B", ":", round(theta_B,4)))
```


### Construct a Metropolis within Gibbs samples, i.e., use a Metropolis algorithm to sample from $\log(\lambda_B) \lvert \log(\lambda_A)$ and then do the viceversa. Also run the chain for $10000$ iterations and costruct density estimates for $\log(\lambda_A)$ and $\log(\lambda_B)$.   

The Gibbs sampler is a MCMC algorithm in which each variable is sampled from its full conditional distribution while keeping the other variables fixed
at their current values. This means that in each iteration, every variable in the model is updated one at a time, sequentially, using its conditional
distribution given the current values of the other variables. The variables are updated in a cyclic manner until convergence is reached.

Gibbs sampling is the optimal choice when the full conditional distributions are easily calculated and sampling from them is feasible.
In this case it is not possible to easily calculate the full conditional distributions, so an implementation of the Metropolis within Gibbs is a better option. 

The Metropolis within Gibbs algorithm is a variation of the Gibbs sampler: it also samples each variable from its conditional distribution given the other
variables. However, instead of directly sampling from the conditional distribution, it employs the Metropolis-Hastings algorithm for acceptance/rejection of proposed values.
The Metropolis within Gibbs algorithm introduces acceptance/rejection steps to handle situations where the conditional distribution of a variable is not
readily available or it is difficult to sample directly from it.

The Metropolis within Gibbs algorithm consists in the following steps

1. Select a variable from the set of variables
2. Propose a new value for the selected variable based on its conditional distribution
3. Calculate the acceptance probability for the proposed value using the Metropolis-Hastings ratio
4. Accept or reject the proposed value based on the acceptance probability
5. Repeat until convergence is reached

In order to sample from the full conditionals, we will need appropriate proposal distribution.
To this end, we will use the conditional distribution obtained from the Laplace's approximation, that we have already calculated:

\begin{equation}
  (\theta_A, \theta_B) \sim \mathcal{N}_2 (\mu, \Sigma)
\end{equation}
With 
\begin{align}
  \mu &= 
    \begin{pmatrix}
      \mu_A \\
      \mu_B \\
    \end{pmatrix} 
  & 
  \Sigma &= 
    \begin{bmatrix}
      \sigma_{1}^2 & \sigma_{1}\sigma_{2}\rho \\
      \sigma_{1}\sigma_{2}\rho & \sigma_{2}^2 \\
    \end{bmatrix}
\end{align}

The conditional distributions are again normal distributions, with parameters: 

\begin{equation}
  (\theta_A | \theta_B) \sim \mathcal{N}_1 \left(\mu_A + \frac{\sigma_1 \rho}{\sigma_2}(\theta_B-\mu_B), \sigma_1^2(1-\rho^2)\right)
\end{equation}

And similarly for $(\theta_B | \theta_A)$, just exchange $\theta_B \leftrightarrow \theta_A$.


```{r echo=TRUE}
# Function to sample from the conditional distribution of theta_A given theta_B
sample_A_given_B <- function(B, A_curr) {
  # proposal parameter
  mu <- mode[1] + (B-mode[2]) * V[1,2] / V[2,2]
  var <- V[1,1] - V[1,2]^2 / V[2,2] 
  # proposal density
  A_prop <- rnorm(1, mean=mu, sd=sqrt(var))
  acceptance_prob <- min(1, target(c(A_prop, B)) * dnorm(A_curr, mean=mu, sd=sqrt(var)) / ( target(c(A_curr, B)) * dnorm(A_prop, mean=mu, sd=sqrt(var)) ))
  if (runif(1) < acceptance_prob){
    return(A_prop)  # Accept the proposal
  }else{
    return(A_curr)  # Reject the proposal
  }
}
# Function to sample from the conditional distribution of theta_B given theta_A
sample_B_given_A <- function(A, B_curr) {
  # proposal parameter
  mu <- mode[2] + (A-mode[1]) * V[1,2] / V[1,1]
  var <- V[2,2] - V[1,2]^2 / V[1,1] 
  # proposal density
  B_prop <- rnorm(1, mean=mu, sd=sqrt(var))
  acceptance_prob <- min(1, target(c(A, B_prop)) * dnorm(B_curr, mean=mu, sd=sqrt(var)) / ( target(c(A, B_curr)) * dnorm(B_prop, mean=mu, sd=sqrt(var)) ))
  if (runif(1) < acceptance_prob){
    return(B_prop)  # Accept the proposal
  }else{
    return(B_curr)  # Reject the proposal
  }
}
# Function to perform Metropolis within Gibbs sampling
metropolis_within_gibbs <- function(n, A_start, B_start) {
  samples <- matrix(nrow = n, ncol = 2)
  A_curr <- A_start
  B_curr <- B_start
  for (i in 1:n) {
    A_curr <- sample_A_given_B(B_curr, A_curr)
    B_curr <- sample_B_given_A(A_curr, B_curr)
    samples[i, ] <- c(A_curr, B_curr)
  }
  return(samples)
}
```

Perform sampling
```{r echo=TRUE}
# Set the initial values and number of samples
A_start <- 3
B_start <- 0
n <- 10000
# Perform Metropolis within Gibbs sampling
samples <- metropolis_within_gibbs(n, A_start, B_start)
```

```{r echo=FALSE}
# trace  to check convergence
par(mfrow = c(1, 2))
plot(1:n,samples[,1], type="l", xlab = expression(i), ylab = expression(theta[A]^(i)))
plot(1:n,samples[,2], type="l", xlab = expression(i), ylab = expression(theta[B]^(i)))
# Restore default plot options
par(mfrow = c(1, 1))
```

Correlation analysis

#### Actually, it does not make much sense for the calculation of the arithmetic mean

```{r echo=TRUE}
acf(samples)
```

In this case neither burn-in phase nor autocorrelation reduction are needed, and we can regard the sample as an IID sample.

```{r echo=FALSE, message=FALSE}
library(gplots)
hist_obj <- hist2d(samples, col=c("aliceblue", heat.colors(12)), main="RWMH sample histogram", xlab = expression(theta[A]), ylab = expression(theta[B]))
```

Finally, density estimates for $\log(\lambda_A)$ and $\log(\lambda_B)$ can be constructed:

```{r echo=TRUE}
theta_A <- mean(samples[,1])
theta_B <- mean(samples[,2])
```

```{r echo=FALSE}
print(paste0("theta_A", ":", round(theta_A,4)))
print(paste0("theta_B", ":", round(theta_B,4)))
```

We conclude noticing that the two sampling algorithms (RWMH and MwG) give very similar results.

```{r echo=FALSE}
# Clear workspace
rm(list=ls())
```


<!-- ----------------------------------------------------------------------------------------------------------------------------------------------- -->

# Exercise 2: Birthweight regression

Dobson (2001) describes a birthweight regression study. One is interested in predicting a baby's birthweight (in grams) based on the gestational age (in weeks) and the gender of the baby. 
The data are available as `birthweight` in the `LearnBayes` R package. In the standard linear regression model, we assume that

$$
BIRTHWEIGHT_i = \beta_0 + \beta_1 AGE_i + \beta_2 GENDER_i + \epsilon_i
$$

Data extraction
```{r echo=TRUE}
library(LearnBayes)
data <- LearnBayes::birthweight
str(data)
```

### Use the R function `lm` to fit this model by least-squares. From the output, assess if the effects `AGE` and `GENDER` are significant, and if they are significant, describe the effects of each covariate on `BIRTHWEIGHT`.

```{r echo=TRUE}
fit <- lm(weight ~ age + gender, data=data)
summary(fit)
```

From the p-values we deduce that `AGE` is the most significant covariate. Its value is positive, as expected, 
since the increasing age of the child should naturally lead to an increase in weight. 

### Suppose a noninformative [Zellner's g prior](https://en.wikipedia.org/wiki/G-prior) is placed on the regression parameter vector $\beta = (\beta_0,\beta_1,\beta_2)$ and assume an Inverse-Gamma priori for $\sigma^2$.


- Simulate a sample of $5000$ draws from the joint posterior distribution of $(\beta,\sigma)$. Explore different values of the prior parameters. To help you on doing this point you might want to read this [slides](./bayes-varsel.pdf)  
- Use the function \texttt{blinreg} in package `LearnBayes` to redo the simulation and compare the results.
- From the simulated samples, compute the posterior means and standard deviations of $\beta_1$ and $\beta_2$.
- Check the consistency of the posterior means and standard deviations with the least-squares estimates and associated standard errors from the `lm` run.
- Suppose one is interested in estimating the expected `birthweight` for `male` and `female` babies of gestational weeks `36` and `40`. From the simulated draws of the posterior distribution construct 90\% interval estimates for 36-week males, 36-week females, 40-week males, and 40-week females.
- Compare the results you obained with those you can have from function `blinregexpected`.
- Suppose instead that one wishes to predict the birthweight for a 36- week male, a 36-week female, a 40-week male, and a 40-week female. Use the simulated data  from the posterior to construct 90\% prediction intervals for the birthweight for each type of baby.
- Compare the results you obained with those you can have from function `blinregpred`



<!--------------------------------------------------------------------------------------------------------------------------------------------------->

# Exercise 3

<!--------------------------------------------------------------------------------------------------------------------------------------------------->

# Exercise 4

<!--------------------------------------------------------------------------------------------------------------------------------------------------->

# References

<!--------------------------------------------------------------------------------------------------------------------------------------------------->